
services:
  bigdata_btl-spark-submit-app:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - SPARK_APPLICATION_PYTHON_LOCATION=/app/main.py
    volumes:
      - ./big_data/src:/app
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - 9870:9870
      - 9000:9000
    environment:
      - CLUSTER_NAME=stock
    env_file:
      - ./hadoop/hadoop.env
    volumes:
      - ./hadoop/namenode:/hadoop/dfs/name
      - C:/BigData/BTL/big_data/Data:/data

  datanode-1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-1
    ports:
      - 50075:50075
    env_file:
      - ./hadoop/hadoop.env
    volumes:
    - ./hadoop/datanode-1:/hadoop/dfs/data
    - C:/BigData/BTL/big_data/Data:/data

  datanode-2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-2
    ports:
      - 9864:9864
    env_file:
      - ./hadoop/hadoop.env
    volumes:
      - ./hadoop/datanode-2:/hadoop/dfs/data
      - C:/BigData/BTL/big_data/Data:/data
#
#  datanode-3:
#    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
#    container_name: datanode-3
#    ports:
#      - 29864:9864
#    env_file:
#      - ./hadoop/hadoop.env
#    volumes:
#      - ./hadoop/datanode-3:/hadoop/dfs/data
#      - D:/bigdata_btl/big_data/Data:/data
#

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master

    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.5
    container_name: elasticsearch
#    volumes:
#      - ./hadoop/esdata:/data
#      - ../storage/esdata:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300
    environment:
#      - xpack.security.enabled=false
      - "discovery.type=single-node"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.5
    container_name: kibana
    ports:
      - 5601:5601
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

networks:
  es-net:
    driver: bridge

